{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dbe417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import RecordVideo\n",
    "gymlogger.set_level(40) #error only\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_video():\n",
    "  mp4list = glob.glob('video/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Could not find video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0fa94e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the environment\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06b072",
   "metadata": {},
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea4876c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00784012 -0.15168767  0.01494143  0.26440138]\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "#Defining Hypermeters\n",
    "#LEARNING_RATE = 0.1\n",
    "LEARNING_RATE = 0.2\n",
    "\n",
    "DISCOUNT = 0.999 #instead of 0.95\n",
    "EPISODES = 60000\n",
    "total = 0\n",
    "total_reward = 0\n",
    "\n",
    "#0.25, 0.25, 0.01, 0.1\n",
    "# Define observation and window size\n",
    "Observation = [40, 40, 50, 50]\n",
    "np_array_win_size = np.array([0.25, 0.25, 0.05, 0.5])\n",
    "\n",
    "epsilon = 0.99\n",
    "epsilon_decay = (epsilon -0.1)/12500\n",
    "epsilon_min = 0.1\n",
    "epsilon_max = 0.95\n",
    "\n",
    "prev_mean = 0\n",
    "obs = env.reset()\n",
    "\n",
    "rewardArr = []\n",
    "\n",
    "new_env = env.step(0)[0]\n",
    "print(new_env)\n",
    "print(round(new_env[2], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5636e52",
   "metadata": {},
   "source": [
    "## Create Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bd47369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 50, 50, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the q table\n",
    "q_table = np.zeros((Observation + [env.action_space.n]))\n",
    "q_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b370e01",
   "metadata": {},
   "source": [
    "## Getting discrete state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5a72593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 2, 9, 11)\n"
     ]
    }
   ],
   "source": [
    "#defining the discrete state\n",
    "def get_discrete_state(state):\n",
    "    \n",
    "    #Given a state, round to the nearest 0.25\n",
    "    #divide by the window size to find which bucket it belongs to\n",
    "    #discrete_state =np.array([np.round(state[0]*4)/4, np.round(state[1] *4) /4, np.round(state[2], 1) ,np.round(state[3], 1)])\n",
    "    #discrete_state =np.array([np.round(state[0]*2)/2, np.round(state[1] *2) /2, np.round(state[2]* 2)/2 ,np.round(state[3]* 2)/2])\n",
    "    discrete_state = state/np_array_win_size+ np.array([15,10,1,10])\n",
    "    #discrete_state = (discrete_state/np_array_win_size)\n",
    "    #print(discrete_state)\n",
    "    return tuple(discrete_state.astype(int))\n",
    "\n",
    "\n",
    "print(get_discrete_state([4, -2, 0.418, 0.63751878]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1e4e8",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d932b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Epsilon: 0.9899287999999999\n",
      "Mean Reward: 0.024\n",
      "Epsilon: 0.9187287999999509\n",
      "Mean Reward: 24.219\n",
      "Episode: 2000\n",
      "Epsilon: 0.8475287999999019\n",
      "Mean Reward: 26.411\n",
      "Epsilon: 0.7763287999998529\n",
      "Mean Reward: 33.214\n",
      "Episode: 4000\n",
      "Epsilon: 0.7051287999998039\n",
      "Mean Reward: 39.925\n",
      "Epsilon: 0.6339287999997549\n",
      "Mean Reward: 46.941\n",
      "Episode: 6000\n",
      "Epsilon: 0.5627287999997059\n",
      "Mean Reward: 55.986\n",
      "Epsilon: 0.49152879999966353\n",
      "Mean Reward: 68.842\n",
      "Episode: 8000\n",
      "Epsilon: 0.42032879999967004\n",
      "Mean Reward: 81.857\n",
      "Epsilon: 0.34912879999967655\n",
      "Mean Reward: 91.808\n",
      "Episode: 10000\n",
      "Epsilon: 0.27792879999968306\n",
      "Mean Reward: 108.978\n",
      "Epsilon: 0.20672879999968957\n",
      "Mean Reward: 117.365\n",
      "Episode: 12000\n",
      "Epsilon: 0.13552879999969608\n",
      "Mean Reward: 145.188\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 146.999\n",
      "Episode: 14000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 166.318\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 170.968\n",
      "Episode: 16000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 173.08\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 180.772\n",
      "Episode: 18000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 181.797\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 182.185\n",
      "Episode: 20000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 183.872\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 193.057\n",
      "Episode: 22000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 182.024\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 205.365\n",
      "Episode: 24000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 204.065\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 189.43\n",
      "Episode: 26000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 204.866\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 216.606\n",
      "Episode: 28000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 208.711\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 227.549\n",
      "Episode: 30000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 239.898\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 226.786\n",
      "Episode: 32000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 221.483\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 253.037\n",
      "Episode: 34000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 247.996\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 251.757\n",
      "Episode: 36000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 269.236\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 293.865\n",
      "Episode: 38000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 337.369\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 343.767\n",
      "Episode: 40000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 328.1\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 484.369\n",
      "Episode: 42000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 331.849\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 383.676\n",
      "Episode: 44000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 468.869\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 294.638\n",
      "Episode: 46000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 396.804\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 440.732\n",
      "Episode: 48000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 292.903\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 359.605\n",
      "Episode: 50000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 464.095\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 479.067\n",
      "Episode: 52000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 359.21\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 425.962\n",
      "Episode: 54000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 312.07\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 292.629\n",
      "Episode: 56000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 574.11\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 597.739\n",
      "Episode: 58000\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 520.87\n",
      "Epsilon: 0.07999279999970116\n",
      "Mean Reward: 381.302\n"
     ]
    }
   ],
   "source": [
    "   for episode in range(EPISODES):\n",
    "        discrete_state = get_discrete_state(env.reset()[0])\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        episode_length = 0\n",
    "\n",
    "        # update every 2000 episodes\n",
    "        if episode % 2000 == 0:\n",
    "            print(\"Episode: \" + str(episode))\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # always get max for now\n",
    "            if np.random.random() > epsilon:\n",
    "                action = np.argmax(q_table[discrete_state])\n",
    "            else:\n",
    "                action = np.random.randint(0, env.action_space.n)\n",
    "\n",
    "            new_env = env.step(action)\n",
    "            new_state = new_env[0]\n",
    "            reward = new_env[1]\n",
    "            done = new_env[2]\n",
    "            episode_reward += reward\n",
    "            episode_length += 1\n",
    "\n",
    "            new_discrete_state = get_discrete_state(new_state)\n",
    "            max_future_q = np.max(q_table[new_discrete_state])\n",
    "            current_q = q_table[discrete_state + (action,)]\n",
    "\n",
    "            # Reward shaping\n",
    "            if done:\n",
    "                if episode_length >= 195:\n",
    "                    reward = 1\n",
    "                else:\n",
    "                    reward = -1\n",
    "            else:\n",
    "                reward = 0.1\n",
    "\n",
    "            new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "            q_table[discrete_state + (action,)] = new_q\n",
    "\n",
    "            discrete_state = new_discrete_state\n",
    "\n",
    "            # check termination conditions\n",
    "            #if abs(new_state[0]) > 2.4 or abs(new_state[2]) > np.radians(12) or episode_length > 500:\n",
    "                 #done = True\n",
    "\n",
    "        total_reward += episode_reward\n",
    "        rewardArr.append(episode_reward)\n",
    "        if epsilon > 0.08:\n",
    "            epsilon -= epsilon_decay\n",
    "        if episode % 1000 == 0:\n",
    "            print(\"Epsilon: \" + str(epsilon))\n",
    "            mean_reward = total_reward / 1000\n",
    "            print(\"Mean Reward: \" + str(mean_reward))\n",
    "\n",
    "            prev_mean = mean_reward\n",
    "            total_reward = 0\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55cb0036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cumulative reward:255.33401666666666\n",
      "Is my agent good enough? True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewardArr)\n",
    "print(\"Average cumulative reward:\" + str(np.mean(rewardArr)))\n",
    "print(\"Is my agent good enough? \" + str(np.mean(rewardArr) > 195))\n",
    "\n",
    "plt.title('Cumulative reward for each episode')\n",
    "plt.ylabel('Cumulative reward')\n",
    "plt.xlabel('episode')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "216b5cb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "pygame is not installed, run `pip install gym[classic_control]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:219\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygame'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m episode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m RecordVideo(gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./video\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m discrete_state \u001b[38;5;241m=\u001b[39m get_discrete_state(observation[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/record_video.py:94\u001b[0m, in \u001b[0;36mRecordVideo.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reset the environment using kwargs and then starts recording if video enabled.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/core.py:323\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ObsType, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/time_limit.py:68\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:42\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/env_checker.py:45\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_reset_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:192\u001b[0m, in \u001b[0;36menv_reset_passive_checker\u001b[0;34m(env, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFuture gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    195\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:206\u001b[0m, in \u001b[0;36mCartPoleEnv.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_beyond_terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), {}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:222\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfxdraw\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygame is not installed, run `pip install gym[classic_control]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pygame\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: pygame is not installed, run `pip install gym[classic_control]`"
     ]
    }
   ],
   "source": [
    "episode_reward = 0\n",
    "\n",
    "env = RecordVideo(gym.make(\"CartPole-v1\", render_mode=\"human\"),\"./video\")\n",
    "observation = env.reset()\n",
    "discrete_state = get_discrete_state(observation[0])\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = np.argmax(q_table[discrete_state])\n",
    "    new_env = env.step(action)\n",
    "    new_state = new_env[0]\n",
    "    reward = new_env[1]\n",
    "    done = new_env[2]\n",
    "    episode_reward += reward\n",
    "    \n",
    "    new_discrete_state = get_discrete_state(new_state)\n",
    "    discrete_state = new_discrete_state\n",
    "\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        discrete_state = get_discrete_state(observation[0])\n",
    "\n",
    "env.close()\n",
    "show_video()\n",
    "print(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc04140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
